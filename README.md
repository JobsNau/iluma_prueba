# Proyecto de Ingenier√≠a de Datos - iluma_prueba

Este proyecto implementa un pipeline completo de ingenier√≠a de datos que procesa una gran cantidad de ofertas laborales, valida su calidad, y las transforma en un modelo relacional normalizado en tercera forma normal (3FN), utilizando Python, PostgreSQL y Docker.

---

## 1. Decisiones de Dise√±o

### üîπ Arquitectura Modular

El c√≥digo est√° estructurado en m√≥dulos especializados, lo que facilita el mantenimiento, la escalabilidad y la colaboraci√≥n entre desarrolladores. Cada m√≥dulo cumple una funci√≥n espec√≠fica dentro del pipeline:

- `ingestion/`: limpieza, transformaci√≥n inicial y carga de los datos crudos.
- `db/`: conexi√≥n a la base de datos, definici√≥n y migraci√≥n del esquema relacional.
- `schemas/`: validaci√≥n de datos utilizando Pandera para asegurar la calidad antes de la carga.
- `tests/`: pruebas automatizadas (con Pytest) para verificar la integridad y consistencia de los datos.
- `utils/`: utilidades y funciones de soporte, como el manejo centralizado de logs y configuraci√≥n.

Esta estructura modular sigue principios de buenas pr√°cticas como la separaci√≥n de responsabilidades, facilitando la extensi√≥n y el testeo del pipeline.

### üîπ Modelo Relacional en 3FN

El modelo de datos fue dise√±ado bajo los principios de la **Tercera Forma Normal (3FN)** con el objetivo de eliminar la redundancia, garantizar la integridad referencial y facilitar el an√°lisis. A continuaci√≥n, se describen los componentes principales del modelo:

#### Tabla de Hechos: `report.jobs`

La tabla principal `report.jobs` representa cada **oferta de trabajo individual** y contiene atributos propios del hecho:

- `title_short`, `title_raw`, `posted_date`, `salary_year_avg`, `salary_hour_avg`, `work_from_home`, `no_degree_mention`, `health_insurance`
- Llaves for√°neas a dimensiones: `company_id`, `location_id`, `schedule_id`, `source_id`, `country_id`, `salary_rate_id`
- `job_row_id`: campo auxiliar √∫nico para trazabilidad contra el archivo original

Esta tabla constituye el **centro del modelo relacional**.

#### Tablas Dimensionales

Para reducir redundancia y permitir una mejor estructura anal√≠tica, se separaron los siguientes atributos en **tablas dimensionales**:

| Tabla                | Descripci√≥n                                                  |
|----------------------|--------------------------------------------------------------|
| `report.companies`   | Empresa que publica la oferta                                |
| `report.locations`   | Ciudad o regi√≥n espec√≠fica de la vacante                     |
| `report.schedules`   | Tipo de jornada laboral (tiempo completo, parcial, etc.)     |
| `report.sources`     | Fuente de publicaci√≥n (Indeed, LinkedIn, etc.)               |
| `report.countries`   | Pa√≠s donde se localiza la oferta                             |
| `report.salary_rates`| Periodicidad del salario (anual o por hora)                  |
| `report.skills`      | Habilidades mencionadas en cada vacante                      |

#### Relaci√≥n muchos-a-muchos: `report.job_skills`

La relaci√≥n entre `jobs` y `skills` es de tipo **muchos a muchos**. Para modelarla correctamente se cre√≥ la tabla intermedia:

```sql
CREATE TABLE report.job_skills (
    job_id INT REFERENCES report.jobs(id),
    skill_id INT REFERENCES report.skills(id),
    PRIMARY KEY (job_id, skill_id)
);
```

#### ‚úÖ Cumplimiento de la 3FN

| Forma Normal | Cumplimiento |
|--------------|--------------|
| **1FN**: campos at√≥micos           | ‚úîÔ∏è Todas las columnas contienen datos simples, sin listas ni diccionarios anidados |
| **2FN**: dependencias completas    | ‚úîÔ∏è Todas las columnas dependen por completo de su clave primaria |
| **3FN**: sin dependencias transitivas | ‚úîÔ∏è No existen atributos que dependan indirectamente de la clave primaria |

---


### üîπ Herramientas Utilizadas

| Herramienta           | Justificaci√≥n                                                                 |
|------------------------|------------------------------------------------------------------------------|
| **PostgreSQL + Docker**| Base de datos relacional confiable y contenedorizada f√°cilmente con Docker. |
| **Python (pandas)**    | Transformaci√≥n eficiente de grandes vol√∫menes de datos tabulares.            |
| **Pandera**            | Validaci√≥n robusta del `DataFrame` antes de la carga en la base de datos.    |
| **Pytest**             | Automatizaci√≥n de pruebas de calidad de datos.                               |
| **Logging**            | Registro profesional de errores, ejecuciones y trazabilidad del pipeline.    |

---

##  2. Instrucciones de Ejecuci√≥n

### üî∏ Requisitos Previos

- Python 3.10+
- Docker y Docker Compose
- Instalar librerias de python. `pip install -r requirements.txt`

### üî∏ Configuraci√≥n Inicial

1. Clonar el repositorio:

```bash
git clone https://github.com/JobsNau/iluma_prueba.git
cd iluma_prueba
```

2. Crear un archivo `.env` en la carpeta `docker/` con el siguiente contenido:

```env
POSTGRES_USER=postgres_user
POSTGRES_PASSWORD=postgres_password
POSTGRES_DB=iluma_db
POSTGRES_PORT=5433
POSTGRES_HOST=localhost
```

3. Levantar el entorno de base de datos:

```bash
docker-compose up -d
```

4. Crear tablas para el modelo relacional

Las definiciones SQL de todas las tablas del modelo relacional (incluyendo `report.jobs`, dimensiones y relaciones) se encuentran en el archivo [`/src/db/schema_report.sql`](./src/db/schema_report.sql).  

Aseg√∫rate de que la base de datos est√© corriendo y que las variables de entorno coincidan con tu configuraci√≥n.

5. Ejecutar el pipeline completo:

```bash
python main.py
```

Esto realiza:

- Limpieza y validaci√≥n del archivo `data_jobs.csv`
- Validaci√≥n con Pandera
- Carga en tabla de staging `carga.data_jobs`
- Transformaci√≥n y normalizaci√≥n a 3FN en `report.*`

---

## 3. Gu√≠a de Testing

### üî∏ Objetivo de las Pruebas

Las pruebas verifican:

- Integridad referencial entre tablas
- Que no existan datos nulos donde no deben
- Que las dimensiones est√©n correctamente pobladas
- Calidad general del proceso de normalizaci√≥n

### üî∏ Ejecuci√≥n Manual de Pruebas

```bash
pytest -v \test
```

### üî∏ Estructura de Pruebas

| Archivo                        | Prop√≥sito                                              |
|-------------------------------|--------------------------------------------------------|
| `test_jobs_table.py`          | Verifica integridad de la tabla principal `report.jobs` |
| `test_foreign_keys.py`        | Comprueba claves for√°neas hacia dimensiones            |
| `test_skills.py`              | Valida relaci√≥n muchos-a-muchos de habilidades         |

---

## Autor

**Jobany Nausa C√°ceres**  
Ingeniero de Datos | Python | PostgreSQL | Docker | ETL


